# -*- coding: utf-8 -*-
"""data_cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SgO__EJusiTWHr-aPqqzT_MryOU9d9WT
"""

# Data Cleaning
# Dataset used: Consolidated JDE 2025 File (JDE_2025_compiled.csv)
# Code done in Google Colab

import pandas as pd
import numpy as np
import re

df = pd.read_csv("/content/drive/MyDrive/TfL files/CLEANED/JDE_2025_compiled.csv", low_memory=False)


# 1 Initial structural inspection

print(f"Rows, Columns: {df.shape}")
print("\nColumn names:")
print(df.columns.tolist())

print("\nData types + non-null counts:")
print(df.info())

print("\nMissing values per column:")
print(df.isna().sum().sort_values(ascending=False))

dup_count = df.duplicated().sum()
print(f"\nDuplicate rows (exact full-row duplicates): {dup_count}")


# 2 Standardise column names

df.columns = (
    df.columns
      .str.strip()
      .str.lower()
      .str.replace(" ", "_", regex=False)
)

print(df.columns.tolist())

def clean_text(x):
    if pd.isna(x):
        return pd.NA
    x = str(x).strip()
    x = re.sub(r"\s+", " ", x)
    return x

def time_of_day_bucket(t):
    if pd.isna(t):
        return pd.NA
    h = t.hour
    if 6 <= h <= 10:
        return "Morning"
    elif 11 <= h <= 13:
        return "Afternoon"
    elif 14 <= h <= 18:
        return "Evening"
    else:
        return "Night"

def parse_duration_text_to_timedelta(x):
    if pd.isna(x):
        return pd.NaT
    s = str(x).strip().lower()
    m = re.match(r"^(?:(\d+)\s*m)?\s*(?:(\d+)\s*s)?$", s)
    if not m:
        return pd.NaT
    minutes = int(m.group(1)) if m.group(1) else 0
    seconds = int(m.group(2)) if m.group(2) else 0
    return pd.to_timedelta(minutes * 60 + seconds, unit="s")

def fmt_td_from_ms(ms_val):
    if pd.isna(ms_val):
        return "NA"
    return str(pd.to_timedelta(ms_val, unit="ms"))

# 3 Convert/clean data types

df["start_datetime"] = pd.to_datetime(df["start_date"], errors="coerce")
df["end_datetime"]   = pd.to_datetime(df["end_date"], errors="coerce")

for col in ["start_station_number", "end_station_number"]:
    df[col] = pd.to_numeric(df[col], errors="coerce").astype("Int64")

for col in ["start_station", "end_station", "bike_model"]:
    df[col] = df[col].map(clean_text)

ms_col = "total_duration_(ms)"
df[ms_col] = pd.to_numeric(df[ms_col], errors="coerce")
df["total_duration_ms"] = df[ms_col].round().astype("Int64")

df["total_duration_td_from_ms"] = pd.to_timedelta(df["total_duration_ms"], unit="ms")
df["total_duration_td_from_text"] = df["total_duration"].map(parse_duration_text_to_timedelta)

df["total_duration_td"] = df["total_duration_td_from_ms"]
df.loc[df["total_duration_td"].isna(), "total_duration_td"] = df["total_duration_td_from_text"]

# 4 Derive temporal features

df["start_date_only"] = df["start_datetime"].dt.date
df["start_time_only"] = df["start_datetime"].dt.time

df["end_date_only"] = df["end_datetime"].dt.date
df["end_time_only"] = df["end_datetime"].dt.time


# 5 Categorise day + time-of-day

df["start_day"] = df["start_datetime"].dt.day_name()
df["end_day"]   = df["end_datetime"].dt.day_name()

df["start_time_of_day"] = df["start_datetime"].dt.time.map(time_of_day_bucket)
df["end_time_of_day"]   = df["end_datetime"].dt.time.map(time_of_day_bucket)


# 6 Convert bike type

bike_map = {
    "CLASSIC": "classic_bike",
    "PBSC_EBIKE": "e_bike",
    "classic": "classic_bike",
    "pbsc_ebike": "e_bike",
}
df["bike_model_clean"] = df["bike_model"].replace(bike_map)


# 7 Remove impossible and extreme durations

# Always compute duration from timestamps
df["duration_from_timestamps"] = df["end_datetime"] - df["start_datetime"]

# Ensure total_duration_td is a real timedelta (safety)
df["total_duration_td"] = pd.to_timedelta(df["total_duration_td"], errors="coerce")

# Summary stats for evidence-based threshold (ms)
ms_series = pd.to_numeric(df[ms_col], errors="coerce")

summary = ms_series.describe(percentiles=[0.01,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.99,0.995,0.999])
print("\nDuration (ms) summary (from total_duration_(ms)):")
print(summary)

min_ms = 60_000
max_ms = ms_series.quantile(0.995)

MIN_DUR = pd.to_timedelta(min_ms, unit="ms")
MAX_DUR = pd.to_timedelta(max_ms, unit="ms")

print(f"\nChosen thresholds:")
print(f"  MIN duration: {min_ms:,} ms  (~{pd.to_timedelta(min_ms, unit='ms')})")
print(f"  MAX duration (99.5th percentile): {int(max_ms):,} ms  (~{pd.to_timedelta(max_ms, unit='ms')})")

# force boolean + fill missing as False
m_start_ok = df["start_datetime"].notna()
m_end_ok   = df["end_datetime"].notna()

m_time_order = (df["duration_from_timestamps"] >= pd.Timedelta(0))
m_time_order = m_time_order.fillna(False)

m_positive_duration = (df["total_duration_td"] > pd.Timedelta(0))
m_positive_duration = m_positive_duration.fillna(False)

m_reasonable = (df["total_duration_td"] >= MIN_DUR) & (df["total_duration_td"] <= MAX_DUR)
m_reasonable = m_reasonable.fillna(False)

TOL = pd.Timedelta(minutes=5)
m_consistent = (df["duration_from_timestamps"].sub(df["total_duration_td"]).abs() <= TOL)
m_consistent = m_consistent.fillna(False)

# convert to plain bool numpy-compatible
mask = (
    m_start_ok.astype(bool)
    & m_end_ok.astype(bool)
    & m_time_order.astype(bool)
    & m_positive_duration.astype(bool)
    & m_reasonable.astype(bool)
    & m_consistent.astype(bool)
)

before_rows = len(df)
df = df.loc[mask].copy()
after_rows = len(df)

print(f"\nRows before duration filters: {before_rows:,}")
print(f"Rows after duration filters:  {after_rows:,}")
print(f"Removed: {(before_rows-after_rows):,}")


# 8) Remove duplicates and invalid rows

df_before = len(df)
df = df.drop_duplicates()
print(f"Exact duplicates removed: {df_before - len(df):,}")

key_required = [
    "start_station_number", "end_station_number",
    "start_station", "end_station",
    "bike_model_clean"
]
df_before = len(df)
for c in key_required:
    df = df[df[c].notna()]
print(f"Rows removed due to missing key fields: {df_before - len(df):,}")


# 9 Final columns

final_df = df[[
    "start_datetime",
    "start_date_only",
    "start_day",
    "start_time_only",
    "start_time_of_day",
    "start_station_number",
    "start_station",
    "end_datetime",
    "end_date_only",
    "end_day",
    "end_time_only",
    "end_time_of_day",
    "end_station_number",
    "end_station",
    "bike_model_clean",
    "total_duration_td",
    ms_col
]].copy()

final_df = final_df.rename(columns={
    "start_date_only": "start_date",
    "start_time_only": "start_time",
    "end_date_only": "end_date",
    "end_time_only": "end_time",
    "bike_model_clean": "bike_model",
    "total_duration_td": "total_duration"
})

print(final_df.head())
print("\nFinal shape:", final_df.shape)

final_df.to_csv("/content/drive/MyDrive/TfL files/CLEANED/JDE_2025_cleanedv2.csv", index=False)
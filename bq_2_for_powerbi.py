# -*- coding: utf-8 -*-
"""bq_2_for_powerbi

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K-YFZQDsQh4RUG2gWJOZaO07ZbJbd0q-
"""

# Export chart datapoints to Excel (for PowerBI)
# Use with bq_2_caculation_modelling.ipynb

export_rows = []

for bike, s in series_by_bike.items():

    train, test, forecast, mae, rmse, fitted = fit_sarimax_arima(
        s, order=(1, 1, 1), train_ratio=0.8
    )

# Build export table for THIS bike type
    temp = pd.DataFrame({
        "date": test.index,
        "bike_type": bike,
        "trips_per_day": test.values,
        "actual_demand": test.values,
        "expected_demand": forecast.values
    })

# Time decomposition
    temp["day"] = temp["date"].dt.day
    temp["month"] = temp["date"].dt.month
    temp["year"] = temp["date"].dt.year

# Model diagnostics
    temp["residual"] = temp["actual_demand"] - temp["expected_demand"]
    temp["abs_error"] = temp["residual"].abs()
    temp["squared_error"] = temp["residual"] ** 2
    temp["pct_error"] = np.where(
        temp["actual_demand"] == 0,
        np.nan,
        (temp["abs_error"] / temp["actual_demand"]) * 100
    )

# Volatility signal
    temp["rolling_7d_std_actual"] = (
        temp["actual_demand"]
        .rolling(window=7, min_periods=3)
        .std()
    )

    temp["rolling_7d_std_residual"] = (
        temp["residual"]
        .rolling(window=7, min_periods=3)
        .std()
    )

    export_rows.append(temp)
export_df = pd.concat(export_rows, ignore_index=True)

# Keep a clear column order
export_df = export_df[[
    "date", "day", "month", "year",
    "bike_type",
    "trips_per_day",
    "actual_demand",
    "expected_demand",
    "residual",
    "abs_error",
    "squared_error",
    "pct_error",
    "rolling_7d_std_actual",
    "rolling_7d_std_residual"
]]


# Save to Excel
out_path = "/content/drive/MyDrive/TfL files/CLEANED/bq_2_for_powerbi.xlsx"
export_df.to_excel(out_path, index=False)

display(export_df.groupby("bike_type").size())